{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from decouple import config\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.schema import Document\n",
    "from langchain_experimental.data_anonymizer import PresidioReversibleAnonymizer\n",
    "from presidio_analyzer import Pattern, PatternRecognizer\n",
    "from textblob import TextBlob\n",
    "from pysentimiento import create_analyzer\n",
    "from accelerate import Accelerator, DataLoaderConfiguration\n",
    "import re\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treść dokumentu do anomizacji wrażliwych dannych, cenzurowania i wykrywania przekleństw i mowy nienawiści "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stworzenie anonymizera z biblioteki PresidioReversibleAnonymizer służącego do anomizacji dannych oraz ustawienie zmiennej add_default_faker_operators na false ponieważ służy ona do zastąpienia danych zanomizowanych na dane fałszywe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "anonymizer = PresidioReversibleAnonymizer(add_default_faker_operators=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podstawowo anonymizer nie rozpoznaje numerów polskich dowodów i numerów kont bankowych z odstępami jako dane wrażliwe więc dodałem do anonymizer'a oba szablony na podstawie regex'ów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "polish_id_pattern = Pattern(name=\"polish_id_pattern\", regex=\"[A-Z]{3}\\d{6}\",score=1)\n",
    "polish_id_recognizer=PatternRecognizer(supported_entity=\"POLISH_ID\",patterns=[polish_id_pattern])\n",
    "anonymizer.add_recognizer(polish_id_recognizer)\n",
    "\n",
    "ssn_pattern = Pattern(name=\"ssn_pattern\", regex=\"(\\d{26}|\\d{2} (\\d{4} ){5}\\d{4})$\", score=1)\n",
    "ssn_recognizer = PatternRecognizer(supported_entity=\"SSN\", patterns=[ssn_pattern])\n",
    "anonymizer.add_recognizer(ssn_recognizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wywołanie anonymizer'a oraz dzięki funkcji print_colored_pii wyswietlenie dokumentu z odznaczającymi się na czerwono placeholderami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_colored_pii(string):\n",
    "  colored_string = re.sub(r\"(<[^>]*>)\", lambda m: \"\\033[31m\" + m.group(1) + \"\\033[0m\",string)\n",
    "  print(colored_string)\n",
    "  \n",
    "reversed_anonymize = anonymizer.anonymize(document_content)\n",
    "print_colored_pii(anonymizer.anonymize(document_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyświetlenie słownika zmianny dannych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W dokumencie nie zostały znaleźone dane wrażliwe\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "if anonymizer.deanonymizer_mapping:\n",
    "    print(\"W dokumencie zostały znaleźone dane wrażliwe\")\n",
    "else:\n",
    "    print(\"W dokumencie nie zostały znaleźone dane wrażliwe\")\n",
    "pprint.pprint(anonymizer.deanonymizer_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomizacja jest również odwraclana\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(anonymizer.deanonymize(reversed_anonymize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykrywanie przekleństw, mowy nienawiści i informacji o stanie zdrowia. Te informacje są wykrywane przez lokalny llm ollama model mistral poprzez wydania polecenia zwrócenia tych danych w cudzysłowie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = Ollama(model=\"mistral\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Your task is to detect swear words, hate speech, and names of illnesses in the given text and return only swear \n",
    "    words, sentences with hate speech and names of illnesses in single \"\"  seperate witchout any other comment:\n",
    "    \n",
    "    text\"{text}\n",
    "    \n",
    "    \"\"\")\n",
    "\n",
    "chain = prompt | ollama | StrOutputParser()\n",
    "\n",
    "response = chain.invoke( {\"text\":reversed_anonymize})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyciągnięcie dannych odpowiedzi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curses = re.findall(r'\"\"(.*?)\"\"', response)\n",
    "print(\"ok\")\n",
    "print(curses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zastąpienie przekleństw, mowy nienawiści i informacji o zdrowiu Placeholderem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def replace_hate_speech(text, placeholder, curses):\n",
    "    blob = TextBlob(text)\n",
    "   \n",
    "    for word in curses:\n",
    "        blob = blob.replace(word, placeholder)\n",
    "    \n",
    "    return str(blob)\n",
    "text_with_placeholders = replace_hate_speech(reversed_anonymize,\"<HATE_SPEECH_or_illnesses>\",curses)\n",
    "\n",
    "print_colored_pii(text_with_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykrywanie mowy nienawiści oraz wyznaczenie jej współczynnika (Im wartość bliższa 1 tym tekst zawiera w sobie więcej mowy nienawiści)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
    "\n",
    "accelerator = Accelerator(dataloader_config=new_config)\n",
    "\n",
    "hatespeech = create_analyzer(task='hate_speech', lang='en')\n",
    "\n",
    "result = hatespeech.predict(document_content)\n",
    "print(result.probas.items())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykrywanie mowy nienawiści na podstawie sentymentu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_hate_speech(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentiment_score = blob.sentiment.polarity\n",
    "    if sentiment_score < -0.5:  \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "if detect_hate_speech(document_content):\n",
    "    print(\"Wykryto mowę nienawiści w tekście.\")\n",
    "else:\n",
    "    print(\"Nie wykryto mowy nienawiści w tekście.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
